{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_excel(\"/kaggle/input/biased/Main.xlsx\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:34.073500Z","iopub.execute_input":"2024-11-24T15:04:34.073845Z","iopub.status.idle":"2024-11-24T15:04:37.483577Z","shell.execute_reply.started":"2024-11-24T15:04:34.073815Z","shell.execute_reply":"2024-11-24T15:04:37.482884Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.485251Z","iopub.execute_input":"2024-11-24T15:04:37.485710Z","iopub.status.idle":"2024-11-24T15:04:37.508439Z","shell.execute_reply.started":"2024-11-24T15:04:37.485671Z","shell.execute_reply":"2024-11-24T15:04:37.507663Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  Batch Source Language  ID  Type  \\\n0   B01         English   1  MAIN   \n1   B01         English   2  MAIN   \n2   B01         English   4  MAIN   \n3   B01         English   7  MAIN   \n4   B01         English   8  MAIN   \n\n                                                Text  \\\n0  Yemen's Houthis have waded into the Israel-Ham...   \n1             Isreal - Hamas Conflict | Face to Face   \n2  Videos show how armed men from Gaza stormed a ...   \n3  Protest in Aligarh Muslim University in suppor...   \n4  IDF releases audio recording about misfired ro...   \n\n                                          English MT  \\\n0  Yemen's Houthis have waded into the Israel-Ham...   \n1             Isreal - Hamas Conflict | Face to Face   \n2  Videos show how armed men from Gaza stormed a ...   \n3  Protest in Aligarh Muslim University in suppor...   \n4  IDF releases audio recording about misfired ro...   \n\n                                           Arabic MT  Annotator ID  \\\n0  خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...           1.0   \n1               إسرائيل - الصراع مع حماس | وجها لوجه           4.0   \n2  أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...           3.0   \n3  وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...           5.0   \n4  الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...           2.0   \n\n                       Bias      Propaganda            Type of Propaganda  \\\n0  Biased against Palestine  Not Propaganda  Propaganda Not to be deleted   \n1                  Unbiased  Not Propaganda                Not Propaganda   \n2                  Unbiased  Not Propaganda  Propaganda Not to be deleted   \n3                  Unbiased  Not Propaganda                Not Propaganda   \n4  Biased against Palestine      Propaganda    Propaganda Must be deleted   \n\n  Type of Bias  Comments  \n0         ضمني       NaN  \n1          NaN       NaN  \n2          NaN       NaN  \n3          NaN       NaN  \n4         ضمني       NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Batch</th>\n      <th>Source Language</th>\n      <th>ID</th>\n      <th>Type</th>\n      <th>Text</th>\n      <th>English MT</th>\n      <th>Arabic MT</th>\n      <th>Annotator ID</th>\n      <th>Bias</th>\n      <th>Propaganda</th>\n      <th>Type of Propaganda</th>\n      <th>Type of Bias</th>\n      <th>Comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B01</td>\n      <td>English</td>\n      <td>1</td>\n      <td>MAIN</td>\n      <td>Yemen's Houthis have waded into the Israel-Ham...</td>\n      <td>Yemen's Houthis have waded into the Israel-Ham...</td>\n      <td>خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...</td>\n      <td>1.0</td>\n      <td>Biased against Palestine</td>\n      <td>Not Propaganda</td>\n      <td>Propaganda Not to be deleted</td>\n      <td>ضمني</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B01</td>\n      <td>English</td>\n      <td>2</td>\n      <td>MAIN</td>\n      <td>Isreal - Hamas Conflict | Face to Face</td>\n      <td>Isreal - Hamas Conflict | Face to Face</td>\n      <td>إسرائيل - الصراع مع حماس | وجها لوجه</td>\n      <td>4.0</td>\n      <td>Unbiased</td>\n      <td>Not Propaganda</td>\n      <td>Not Propaganda</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B01</td>\n      <td>English</td>\n      <td>4</td>\n      <td>MAIN</td>\n      <td>Videos show how armed men from Gaza stormed a ...</td>\n      <td>Videos show how armed men from Gaza stormed a ...</td>\n      <td>أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...</td>\n      <td>3.0</td>\n      <td>Unbiased</td>\n      <td>Not Propaganda</td>\n      <td>Propaganda Not to be deleted</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B01</td>\n      <td>English</td>\n      <td>7</td>\n      <td>MAIN</td>\n      <td>Protest in Aligarh Muslim University in suppor...</td>\n      <td>Protest in Aligarh Muslim University in suppor...</td>\n      <td>وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...</td>\n      <td>5.0</td>\n      <td>Unbiased</td>\n      <td>Not Propaganda</td>\n      <td>Not Propaganda</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B01</td>\n      <td>English</td>\n      <td>8</td>\n      <td>MAIN</td>\n      <td>IDF releases audio recording about misfired ro...</td>\n      <td>IDF releases audio recording about misfired ro...</td>\n      <td>الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...</td>\n      <td>2.0</td>\n      <td>Biased against Palestine</td>\n      <td>Propaganda</td>\n      <td>Propaganda Must be deleted</td>\n      <td>ضمني</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.509398Z","iopub.execute_input":"2024-11-24T15:04:37.509731Z","iopub.status.idle":"2024-11-24T15:04:37.514894Z","shell.execute_reply.started":"2024-11-24T15:04:37.509692Z","shell.execute_reply":"2024-11-24T15:04:37.514033Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['Batch', 'Source Language', 'ID', 'Type', 'Text', 'English MT',\n       'Arabic MT', 'Annotator ID', 'Bias', 'Propaganda', 'Type of Propaganda',\n       'Type of Bias', 'Comments'],\n      dtype='object')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df = df.drop(columns=['Annotator ID', 'Text','Batch', 'ID', 'Comments', 'Type', 'Source Language', 'English MT',\"Type of Bias\",\"Propaganda\",\"Type of Propaganda\"], errors='ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.516479Z","iopub.execute_input":"2024-11-24T15:04:37.516727Z","iopub.status.idle":"2024-11-24T15:04:37.528369Z","shell.execute_reply.started":"2024-11-24T15:04:37.516704Z","shell.execute_reply":"2024-11-24T15:04:37.527581Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.529341Z","iopub.execute_input":"2024-11-24T15:04:37.529575Z","iopub.status.idle":"2024-11-24T15:04:37.545025Z","shell.execute_reply.started":"2024-11-24T15:04:37.529552Z","shell.execute_reply":"2024-11-24T15:04:37.544314Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                           Arabic MT                      Bias\n0  خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...  Biased against Palestine\n1               إسرائيل - الصراع مع حماس | وجها لوجه                  Unbiased\n2  أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...                  Unbiased\n3  وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...                  Unbiased\n4  الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...  Biased against Palestine","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arabic MT</th>\n      <th>Bias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...</td>\n      <td>Biased against Palestine</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>إسرائيل - الصراع مع حماس | وجها لوجه</td>\n      <td>Unbiased</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...</td>\n      <td>Unbiased</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...</td>\n      <td>Unbiased</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...</td>\n      <td>Biased against Palestine</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"total_rows = len(df)\nprint(f\"Total number of rows: {total_rows}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.545913Z","iopub.execute_input":"2024-11-24T15:04:37.546233Z","iopub.status.idle":"2024-11-24T15:04:37.555095Z","shell.execute_reply.started":"2024-11-24T15:04:37.546177Z","shell.execute_reply":"2024-11-24T15:04:37.554301Z"}},"outputs":[{"name":"stdout","text":"Total number of rows: 13500\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.556129Z","iopub.execute_input":"2024-11-24T15:04:37.556361Z","iopub.status.idle":"2024-11-24T15:04:37.568984Z","shell.execute_reply.started":"2024-11-24T15:04:37.556338Z","shell.execute_reply":"2024-11-24T15:04:37.568200Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Arabic MT       0\nBias         2700\ndtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.569846Z","iopub.execute_input":"2024-11-24T15:04:37.570129Z","iopub.status.idle":"2024-11-24T15:04:37.578243Z","shell.execute_reply.started":"2024-11-24T15:04:37.570090Z","shell.execute_reply":"2024-11-24T15:04:37.577470Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df.replace(['', 'None', 'nan'], np.nan, inplace=True)  \ndf.dropna(subset=['Bias'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.579345Z","iopub.execute_input":"2024-11-24T15:04:37.579610Z","iopub.status.idle":"2024-11-24T15:04:37.596607Z","shell.execute_reply.started":"2024-11-24T15:04:37.579588Z","shell.execute_reply":"2024-11-24T15:04:37.595688Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.599927Z","iopub.execute_input":"2024-11-24T15:04:37.600212Z","iopub.status.idle":"2024-11-24T15:04:37.607301Z","shell.execute_reply.started":"2024-11-24T15:04:37.600186Z","shell.execute_reply":"2024-11-24T15:04:37.606358Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Arabic MT    0\nBias         0\ndtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"total_rows = len(df)\nprint(f\"Total number of rows: {total_rows}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.608326Z","iopub.execute_input":"2024-11-24T15:04:37.608571Z","iopub.status.idle":"2024-11-24T15:04:37.619189Z","shell.execute_reply.started":"2024-11-24T15:04:37.608547Z","shell.execute_reply":"2024-11-24T15:04:37.618345Z"}},"outputs":[{"name":"stdout","text":"Total number of rows: 10800\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(df['Bias'].cat.categories if df['Bias'].dtype.name == 'category' else df['Bias'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.620203Z","iopub.execute_input":"2024-11-24T15:04:37.620431Z","iopub.status.idle":"2024-11-24T15:04:37.635911Z","shell.execute_reply.started":"2024-11-24T15:04:37.620408Z","shell.execute_reply":"2024-11-24T15:04:37.635050Z"}},"outputs":[{"name":"stdout","text":"['Biased against Palestine' 'Unbiased' 'Unclear' 'Biased against others'\n 'Biased against Israel' 'Biased against both Palestine and Israel'\n 'Not Applicable']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"columns_to_check = ['Bias']\n\nfor column in columns_to_check:\n    print(f\"Class counts for '{column}':\")\n    print(df[column].value_counts())\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.636869Z","iopub.execute_input":"2024-11-24T15:04:37.637075Z","iopub.status.idle":"2024-11-24T15:04:37.647656Z","shell.execute_reply.started":"2024-11-24T15:04:37.637053Z","shell.execute_reply":"2024-11-24T15:04:37.646873Z"}},"outputs":[{"name":"stdout","text":"Class counts for 'Bias':\nBias\nUnbiased                                    6817\nBiased against Palestine                    2900\nUnclear                                      432\nBiased against Israel                        281\nBiased against others                        203\nNot Applicable                               120\nBiased against both Palestine and Israel      47\nName: count, dtype: int64\n\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install emoji","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:37.648770Z","iopub.execute_input":"2024-11-24T15:04:37.649115Z","iopub.status.idle":"2024-11-24T15:04:46.607493Z","shell.execute_reply.started":"2024-11-24T15:04:37.649078Z","shell.execute_reply":"2024-11-24T15:04:46.606605Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (2.13.2)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import re\nimport emoji\n\ndef preprocess_text(text):\n    # Ensure text is a string\n    text = str(text)\n    \n    # 1. Remove hashtags\n    text = re.sub(r'#\\w+', '', text)\n    \n    # 2. Remove full URLs with protocols (e.g., \"http://example.com\")\n    text = re.sub(r'https?://\\S+|www\\.\\S+|bit\\.ly\\S*', '', text)\n    \n    # 3. Remove standalone paths without protocols (e.g., \"/content/kan-news/defense/629514/\")\n    text = re.sub(r'/\\S+', '', text)\n    \n    # 4. Remove emails\n    text = re.sub(r'\\S+@\\S+', '', text)\n    \n    # 5. Remove emojis\n    text = emoji.replace_emoji(text, replace='')\n    \n    # 6. Remove diacritics\n    arabic_diacritics = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n    text = re.sub(arabic_diacritics, '', text)\n    \n    # 7. Remove Tatweel (ـ)\n    text = re.sub(r'ـ', '', text)\n    \n    # 8. Normalize Arabic text\n    text = re.sub(r'[إأآا]', 'ا', text)  # Unify Alif variants\n    text = re.sub(r'ة', 'ه', text)  # Replace Taa Marbuta with Haa\n    text = re.sub(r'ى', 'ي', text)  # Replace Alef Maqsura with Ya\n    \n    # 9. Remove repeated characters (e.g., \"ممتتتاز\" → \"ممتاز\")\n    text = re.sub(r'(.)\\1+', r'\\1', text)\n    \n    # Return cleaned text\n    return text\n# Apply the preprocessing function\ndf['Arabic MT'] = df['Arabic MT'].apply(preprocess_text)\ndf['Arabic MT'][9022]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:46.608950Z","iopub.execute_input":"2024-11-24T15:04:46.609271Z","iopub.status.idle":"2024-11-24T15:04:49.817476Z","shell.execute_reply.started":"2024-11-24T15:04:46.609242Z","shell.execute_reply":"2024-11-24T15:04:49.816595Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'اولا علي قناه ABC: جلست المرشحه الرئاسيه الجمهوريه نيكي هيلي مع لينسي ديفيس من قناه ABC News، حيث ناقشت مجموعه واسعه من المواضيع بما في ذلك الرئيس السابق. ترامب والحرب بين اسرائيل وحماس والاجهاض وحياتها قبل ان تظهر امام الجمهور. اقرا المزيد: '"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"!pip install tensorflow\n!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:04:49.818381Z","iopub.execute_input":"2024-11-24T15:04:49.818602Z","iopub.status.idle":"2024-11-24T15:05:02.177879Z","shell.execute_reply.started":"2024-11-24T15:04:49.818580Z","shell.execute_reply":"2024-11-24T15:05:02.176700Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mCollecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import BorderlineSMOTE\nimport numpy as np\n\nmodel = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n\nX = df['Arabic MT']\ny = df['Bias']\n\nX_embeddings = model.encode(X.tolist(), convert_to_numpy=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:05:02.179435Z","iopub.execute_input":"2024-11-24T15:05:02.179770Z","iopub.status.idle":"2024-11-24T15:07:18.947914Z","shell.execute_reply.started":"2024-11-24T15:05:02.179741Z","shell.execute_reply":"2024-11-24T15:07:18.947137Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfe948b2fad44a782f0115cda78345a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75a9744e6db42f3ab7602452dbf6cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b680524088e7421c8a1b2174a240b09c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad944b6ee28244f1a57218494f4bbc41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99f8ab0a120b42a6bee8e6022580ba9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ecc54c500f8491689f27010649b57eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3db18c2dac8414292b3626ba38966d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b452c6714d95410cb309bff691335399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0660d913836749f2a99cebed84c436e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf16352c84d443ca87389de30784b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/338 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccad7392987642db970423679257c9f5"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from imblearn.over_sampling import BorderlineSMOTE\n\nborderline_smote = BorderlineSMOTE(random_state=42)\nX_train_resampled, y_train_resampled = borderline_smote.fit_resample(X_train, y_train)\n\nprint(\"Class distribution after Borderline-SMOTE:\")\nprint(pd.Series(y_train_resampled).value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:07:18.948922Z","iopub.execute_input":"2024-11-24T15:07:18.949518Z","iopub.status.idle":"2024-11-24T15:07:20.505415Z","shell.execute_reply.started":"2024-11-24T15:07:18.949488Z","shell.execute_reply":"2024-11-24T15:07:20.504481Z"}},"outputs":[{"name":"stdout","text":"Class distribution after Borderline-SMOTE:\nBias\nUnbiased                                    5454\nBiased against Palestine                    5454\nUnclear                                     5454\nBiased against Israel                       5454\nBiased against others                       5454\nBiased against both Palestine and Israel    5454\nNot Applicable                              5454\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\noriginal_embeddings = X_train\nsynthetic_embeddings = X_train_resampled[len(X_train):]\n\ncos_sim = cosine_similarity(original_embeddings, synthetic_embeddings)\naverage_similarity = np.mean(np.max(cos_sim, axis=0))\nprint(f\"Average Cosine Similarity of Synthetic Samples: {average_similarity:.4f}\")\n\nif average_similarity < 0.7:\n    print(\"Warning: Synthetic samples are significantly different from the original data.\")\nelse:\n    print(\"Synthetic samples appear similar to the original data.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:07:20.506606Z","iopub.execute_input":"2024-11-24T15:07:20.506924Z","iopub.status.idle":"2024-11-24T15:07:22.691664Z","shell.execute_reply.started":"2024-11-24T15:07:20.506898Z","shell.execute_reply":"2024-11-24T15:07:22.690613Z"}},"outputs":[{"name":"stdout","text":"Average Cosine Similarity of Synthetic Samples: 0.9886\nSynthetic samples appear similar to the original data.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\n\n# Define Dataset Class\nclass TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        # Prepare input for T5\n        input_text = f\"classify: {text}\"\n        \n        encoding = self.tokenizer(\n            input_text,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        target_encoding = self.tokenizer(\n            label,\n            max_length=10,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        \n        return {\n            \"input_ids\": encoding[\"input_ids\"].flatten(),\n            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n            \"labels\": target_encoding[\"input_ids\"].flatten(),\n        }\n\n# Tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\n# Prepare Dataset\nmax_len = 128  # Adjust based on your data\ntrain_dataset = TextClassificationDataset(\n    texts=X_train_resampled,\n    labels=y_train_resampled.tolist(),\n    tokenizer=tokenizer,\n    max_len=max_len,\n)\nval_dataset = TextClassificationDataset(\n    texts=X_test.tolist(),\n    labels=y_test.tolist(),\n    tokenizer=tokenizer,\n    max_len=max_len,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:57:59.433120Z","iopub.execute_input":"2024-11-24T15:57:59.433441Z","iopub.status.idle":"2024-11-24T15:57:59.865368Z","shell.execute_reply.started":"2024-11-24T15:57:59.433413Z","shell.execute_reply":"2024-11-24T15:57:59.864679Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:58:23.405510Z","iopub.execute_input":"2024-11-24T15:58:23.406187Z","iopub.status.idle":"2024-11-24T15:58:23.410427Z","shell.execute_reply.started":"2024-11-24T15:58:23.406155Z","shell.execute_reply":"2024-11-24T15:58:23.409587Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from transformers import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom tqdm import tqdm\n\n# Load T5 model\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\nmodel = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Training Loop\ndef train_epoch(model, data_loader, optimizer):\n    model.train()\n    losses = []\n    for batch in tqdm(data_loader, desc=\"Training\"):\n        input_ids = batch[\"input_ids\"].to(model.device)\n        attention_mask = batch[\"attention_mask\"].to(model.device)\n        labels = batch[\"labels\"].to(model.device)\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels,\n        )\n        loss = outputs.loss\n        losses.append(loss.item())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    return sum(losses) / len(losses)\n\n# Evaluation Loop\ndef eval_model(model, data_loader):\n    model.eval()\n    losses = []\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(model.device)\n            attention_mask = batch[\"attention_mask\"].to(model.device)\n            labels = batch[\"labels\"].to(model.device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels,\n            )\n            loss = outputs.loss\n            losses.append(loss.item())\n    return sum(losses) / len(losses)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:58:47.551890Z","iopub.execute_input":"2024-11-24T15:58:47.552557Z","iopub.status.idle":"2024-11-24T15:58:48.159544Z","shell.execute_reply.started":"2024-11-24T15:58:47.552526Z","shell.execute_reply":"2024-11-24T15:58:48.158654Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"epochs = 5\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    train_loss = train_epoch(model, train_loader, optimizer)\n    val_loss = eval_model(model, val_loader)\n    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:59:21.166694Z","iopub.execute_input":"2024-11-24T15:59:21.167027Z","iopub.status.idle":"2024-11-24T16:20:27.412827Z","shell.execute_reply.started":"2024-11-24T15:59:21.166995Z","shell.execute_reply":"2024-11-24T16:20:27.412036Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2387/2387 [03:08<00:00, 12.63it/s]\nEvaluating: 100%|██████████| 135/135 [01:00<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4314, Val Loss: 0.2007\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2387/2387 [03:09<00:00, 12.60it/s]\nEvaluating: 100%|██████████| 135/135 [01:04<00:00,  2.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2023, Val Loss: 0.1704\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2387/2387 [03:10<00:00, 12.52it/s]\nEvaluating: 100%|██████████| 135/135 [01:03<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1868, Val Loss: 0.1755\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2387/2387 [03:10<00:00, 12.52it/s]\nEvaluating: 100%|██████████| 135/135 [01:03<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1765, Val Loss: 0.1940\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2387/2387 [03:10<00:00, 12.51it/s]\nEvaluating: 100%|██████████| 135/135 [01:03<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1686, Val Loss: 0.1615\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef eval_model_with_accuracy(model, data_loader, tokenizer):\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(model.device)\n            attention_mask = batch[\"attention_mask\"].to(model.device)\n            labels = batch[\"labels\"].to(model.device)\n\n            # Generate predictions\n            outputs = model.generate(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                max_length=10,\n            )\n            \n            # Decode predictions and labels\n            predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n            true_labels = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n            \n            # Count correct predictions\n            for pred, true_label in zip(predictions, true_labels):\n                if pred.strip() == true_label.strip():\n                    total_correct += 1\n            total_samples += len(true_labels)\n    \n    # Calculate accuracy\n    accuracy = total_correct / total_samples\n    return accuracy\n\n# Example usage\naccuracy = eval_model_with_accuracy(model, val_loader, tokenizer)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:31:55.392245Z","iopub.execute_input":"2024-11-24T16:31:55.393040Z","iopub.status.idle":"2024-11-24T16:33:04.631188Z","shell.execute_reply.started":"2024-11-24T16:31:55.393007Z","shell.execute_reply":"2024-11-24T16:33:04.630365Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 135/135 [01:09<00:00,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 23.01%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}